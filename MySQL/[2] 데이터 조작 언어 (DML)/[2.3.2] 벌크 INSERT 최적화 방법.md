# 벌크 INSERT 최적화 방법

벌크 INSERT는 대량의 데이터를 DB에 효율적으로 삽입하는 기법임. 적절히 사용하면 성능을 크게 향상시킬 수 있음.

## 다중 행 INSERT

기본적인 벌크 INSERT 방식. 여러 행을 하나의 쿼리로 삽입함.

```sql
INSERT INTO users (name, email, created_at)
VALUES 
    ('Alice', 'alice@example.com', NOW()),
    ('Bob', 'bob@example.com', NOW()),
    ('Charlie', 'charlie@example.com', NOW());
```

이 방식은 네트워크 왕복과 쿼리 파싱 오버헤드를 줄여줌.

## 배치 크기 최적화

너무 큰 배치는 메모리 문제를 일으킬 수 있고, 너무 작은 배치는 효율이 떨어짐.

```python
batch_size = 1000
values = []
for row in data:
    values.append((row['name'], row['email'], row['created_at']))
    if len(values) >= batch_size:
        cursor.executemany(
            "INSERT INTO users (name, email, created_at) VALUES (%s, %s, %s)",
            values
        )
        values = []
```

최적의 배치 크기는 데이터 특성과 시스템 리소스에 따라 다름. 보통 500~5000 사이가 적당함.

## 트랜잭션 사용

여러 INSERT를 하나의 트랜잭션으로 묶어 처리함.

```sql
START TRANSACTION;
INSERT INTO users ...;
INSERT INTO users ...;
INSERT INTO users ...;
COMMIT;
```

트랜잭션은 데이터 일관성을 보장하고, 커밋 오버헤드를 줄여줌.

## 임시적 인덱스 비활성화

대량 삽입 시 인덱스 갱신 비용이 높음. 임시로 인덱스를 비활성화하면 성능이 개선됨.

```sql
ALTER TABLE users DISABLE KEYS;
-- 대량 INSERT 수행
ALTER TABLE users ENABLE KEYS;
```

주의: 프라이머리 키와 유니크 인덱스는 비활성화할 수 없음.

## LOAD DATA INFILE 사용

외부 파일에서 직접 데이터를 로드하는 방식. 매우 빠름.

```sql
LOAD DATA INFILE '/path/to/data.csv'
INTO TABLE users
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;
```

보안 설정에 주의해야 하며, 파일 형식을 정확히 지정해야 함.

## 파티션 테이블 활용

대규모 데이터의 경우, 파티션 테이블을 사용해 병렬 삽입이 가능함.

```sql
CREATE TABLE logs (
    id INT AUTO_INCREMENT,
    log_date DATE,
    message TEXT,
    PRIMARY KEY (id, log_date)
) PARTITION BY RANGE (TO_DAYS(log_date)) (
    PARTITION p0 VALUES LESS THAN (TO_DAYS('2023-01-01')),
    PARTITION p1 VALUES LESS THAN (TO_DAYS('2023-04-01')),
    PARTITION p2 VALUES LESS THAN (TO_DAYS('2023-07-01')),
    PARTITION p3 VALUES LESS THAN MAXVALUE
);
```

파티션별로 동시에 데이터를 삽입할 수 있어 성능이 향상됨.

## 준비된 문(Prepared Statements) 사용

동일한 구조의 쿼리를 반복 실행할 때 유용함.

```python
stmt = "INSERT INTO users (name, email) VALUES (%s, %s)"
cursor.prepare(stmt)

for user in user_data:
    cursor.execute(None, (user['name'], user['email']))
```

쿼리 파싱 오버헤드를 줄이고 SQL 인젝션 방지에도 도움이 됨.

## 벌크 UPSERT 최적화

INSERT ... ON DUPLICATE KEY UPDATE를 사용한 벌크 작업도 가능함.

```sql
INSERT INTO product_inventory (product_id, quantity)
VALUES 
    (101, 50),
    (102, 30),
    (103, 20)
ON DUPLICATE KEY UPDATE
quantity = quantity + VALUES(quantity);
```

이 방식으로 여러 제품의 재고를 한 번에 업데이트할 수 있음.

벌크 INSERT 최적화는 데이터 크기, 하드웨어 성능, 네트워크 상태 등 여러 요인에 영향을 받음. 실제 데이터로 벤치마크 테스트를 수행해 최적의 방법을 찾는 게 중요함. 또한, 데이터 무결성과 일관성을 유지하면서 성능을 개선해야 함.
